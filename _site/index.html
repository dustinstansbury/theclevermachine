<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
   <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>
  
  <link rel="stylesheet" href="/theclevermachine/assets/main.css"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>The Clever Machine | Musings on data and science</title>
<meta name="generator" content="Jekyll v3.8.7" />
<meta property="og:title" content="The Clever Machine" />
<meta name="author" content="Dustin Stansbury, PhD" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Musings on data and science" />
<meta property="og:description" content="Musings on data and science" />
<link rel="canonical" href="https://dustinstansbury.github.io/theclevermachine/" />
<meta property="og:url" content="https://dustinstansbury.github.io/theclevermachine/" />
<meta property="og:site_name" content="The Clever Machine" />
<script type="application/ld+json">
{"author":{"@type":"Person","name":"Dustin Stansbury, PhD"},"url":"https://dustinstansbury.github.io/theclevermachine/","description":"Musings on data and science","@type":"WebSite","headline":"The Clever Machine","name":"The Clever Machine","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link type="application/atom+xml" rel="alternate" href="https://dustinstansbury.github.io/theclevermachine/feed.xml" title="The Clever Machine" /><!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-XXXXXXXX-X"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-171913050-1');
</script>

  

</head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/theclevermachine/">The Clever Machine</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/theclevermachine/about/">About</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <div class="home">
<h2 class="post-list-heading">Posts</h2>
    <ul class="post-list"><li><span class="post-meta">Jul 13, 2020</span>
        <h3>
          <a class="post-link" href="/theclevermachine/a-gentle-introduction-to-neural-networks">
            A Gentle Introduction to Artificial Neural Networks
          </a>
        </h3><p>Though many phenomena in the world can be well-modeled using basic linear regression or classification, there are also many interesting phenomena that are nonlinear in nature. In order to deal with nonlinear phenomena, there have been a diversity of nonlinear models developed.</p>

</li><li><span class="post-meta">Jun 30, 2020</span>
        <h3>
          <a class="post-link" href="/theclevermachine/cutting-your-losses">
            Cutting Your Losses: Loss Functions &amp; the Sum of Squared Errors Loss
          </a>
        </h3><p>In this post we’ll introduce the notion of the loss function and its role in model parameter estimation. We’ll then focus in on a common loss function–the sum of squared errors (SSE) loss–and give some motivations and intuitions as to why this particular loss function works so well in practice.</p>

</li><li><span class="post-meta">Jun 29, 2020</span>
        <h3>
          <a class="post-link" href="/theclevermachine/derivation-ols-normal-equations">
            Derivation: Ordinary Least Squares Solution and Normal Equations
          </a>
        </h3><p>In a linear regression framework, we assume some output variable <script type="math/tex">y</script> is a linear combination of some independent input variables <script type="math/tex">X</script> plus some independent noise <script type="math/tex">\epsilon</script>. The way the independent variables are combined is defined by a parameter vector <script type="math/tex">\beta</script>:</p>

</li><li><span class="post-meta">Jun 29, 2020</span>
        <h3>
          <a class="post-link" href="/theclevermachine/derivation-common-neural-network-activation-functions">
            Derivation: Derivatives for Common Neural Network Activation Functions
          </a>
        </h3><p>When constructing Artificial Neural Network (ANN) models, one of the primary considerations is choosing activation functions for hidden and output layers that are differentiable. This is because calculating the backpropagated error signal that is used to determine ANN parameter updates requires the gradient of the activation function gradient . Three of the most commonly-used activation functions used in ANNs are the identity function, the logistic sigmoid function, and the hyperbolic tangent function. Examples of these functions and their associated gradients (derivatives in 1D) are plotted in Figure 1.</p>

</li><li><span class="post-meta">Jun 29, 2020</span>
        <h3>
          <a class="post-link" href="/theclevermachine/derivation-backpropagation">
            Derivation: Error Backpropagation &amp; Gradient Descent for Neural Networks
          </a>
        </h3><p>Artificial neural networks (ANNs) are a powerful class of models used for nonlinear regression and classification tasks that are motivated by biological neural computation. The general idea behind ANNs is pretty straightforward: map some input onto a desired target value using a distributed cascade of nonlinear transformations (see <strong><em>Figure 1</em></strong>). However, for many, myself included, the learning algorithm used to train ANNs can be difficult to get your head around at first. In this post I give a step-by-step walkthrough of the derivation of the gradient descent algorithm commonly used to train ANNs–aka the “backpropagation” algorithm. Along the way, I’ll also try to provide some high-level insights into the computations being performed during learning<sup id="fnref:1"><a href="#fn:1" class="footnote">1</a></sup>.</p>

<div class="footnotes">
  <ol>
    <li id="fn:1">
      <p>Though, I guess these days with autograd, who <em>really</em> needs to understand how the calculus for gradient descent works, amiright? (<em>hint</em>: that is a joke) <a href="#fnref:1" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
</li></ul>

    <p class="rss-subscribe">subscribe <a href="/theclevermachine/feed.xml">via RSS</a></p></div>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/theclevermachine/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">The Clever Machine</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">Dustin Stansbury, PhD</li><li><a class="u-email" href="mailto:[first_name][dot][last_name][at][google email][dotcom]">[first_name][dot][last_name][at][google email][dotcom]</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/dustinstansbury"><svg class="svg-icon"><use xlink:href="/theclevermachine/assets/minima-social-icons.svg#github"></use></svg> <span class="username">dustinstansbury</span></a></li><li><a href="https://www.twitter.com/corrcoef"><svg class="svg-icon"><use xlink:href="/theclevermachine/assets/minima-social-icons.svg#twitter"></use></svg> <span class="username">corrcoef</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>Musings on data and science</p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
